# app.py ‚Äî b·∫£n fix ƒë·∫ßy ƒë·ªß cho c·∫£ LAWBank v√† CABBANK
import streamlit as st
from docx import Document
import re
import math
import pandas as pd

# ====================================================
# ‚öôÔ∏è H√ÄM CHUNG
# ====================================================
def clean_text(s: str) -> str:
    if s is None:
        return ""
    return re.sub(r'\s+', ' ', s).strip()

def read_docx_paragraphs(source):
    """ƒê·ªçc file Word v√† tr·∫£ v·ªÅ danh s√°ch ƒëo·∫°n text kh√¥ng r·ªóng."""
    try:
        doc = Document(source)
    except Exception as e:
        st.error(f"Kh√¥ng th·ªÉ ƒë·ªçc file .docx: {e}")
        return []
    paras = [p.text.strip() for p in doc.paragraphs if p.text and p.text.strip()]
    return paras

# ====================================================
# üß© PARSER CABBANK (K·ª∏ THU·∫¨T)
# ====================================================
def parse_cabbank(source):
    paras = read_docx_paragraphs(source)
    if not paras:
        return []

    questions = []
    current = {"question": "", "options": [], "answer": ""}
    opt_pat = re.compile(r'(?P<star>\*)?\s*(?P<letter>[A-Da-d])\s*(?:\.\s*|\)\s*)')

    for p in paras:
        matches = list(opt_pat.finditer(p))
        if not matches:
            if current["options"]:
                if current["question"] and current["options"]:
                    if not current["answer"]:
                        current["answer"] = current["options"][0]
                    current["question"] = clean_text(current["question"])
                    current["options"] = [clean_text(o) for o in current["options"]]
                    current["answer"] = clean_text(current["answer"])
                    questions.append(current)
                current = {"question": clean_text(p), "options": [], "answer": ""}
            else:
                current["question"] = (current["question"] + " " + p).strip() if current["question"] else clean_text(p)
            continue

        first_match = matches[0]
        pre_text = p[:first_match.start()].strip()
        if pre_text:
            if current["options"]:
                if current["question"] and current["options"]:
                    if not current["answer"]:
                        current["answer"] = current["options"][0]
                    current["question"] = clean_text(current["question"])
                    current["options"] = [clean_text(o) for o in current["options"]]
                    current["answer"] = clean_text(current["answer"])
                    questions.append(current)
                current = {"question": clean_text(pre_text), "options": [], "answer": ""}
            else:
                current["question"] = (current["question"] + " " + pre_text).strip() if current["question"] else clean_text(pre_text)

        for idx, m in enumerate(matches):
            start = m.end()
            end = matches[idx+1].start() if idx+1 < len(matches) else len(p)
            opt_body = p[start:end].strip()
            opt_body = clean_text(opt_body)
            letter = m.group("letter").lower()
            option_text = f"{letter}. {opt_body}" if opt_body else f"{letter}."
            current["options"].append(option_text)
            if m.group("star"):
                current["answer"] = option_text

    if current["question"] and current["options"]:
        if not current["answer"]:
            current["answer"] = current["options"][0]
        current["question"] = clean_text(current["question"])
        current["options"] = [clean_text(o) for o in current["options"]]
        current["answer"] = clean_text(current["answer"])
        questions.append(current)

    return questions

# ====================================================
# üß© PARSER LAWBANK (LU·∫¨T)
# ====================================================
def parse_lawbank(source):
    """ƒê·ªçc ng√¢n h√†ng c√¢u h·ªèi d·∫°ng ƒë√°nh s·ªë 1., 2., 3... c√≥ d√≤ng REF, x√≥a REF v√† x√°c ƒë·ªãnh ƒë√°p √°n *a/*b/..."""
    paras = read_docx_paragraphs(source)
    if not paras:
        return []

    # G·ªôp c√°c ƒëo·∫°n l·∫°i, th√™m xu·ªëng d√≤ng gi·ªØa c√°c ƒëo·∫°n
    text = "\n".join(paras)

    # Chu·∫©n h√≥a: n·∫øu thi·∫øu xu·ªëng d√≤ng gi·ªØa c√°c c√¢u h·ªèi (v√≠ d·ª• "1.Who..." d√≠nh v√†o "2.What...")
    text = re.sub(r'(?<=\d)\.(?=\S)', '. ', text)

    # T√°ch th√†nh t·ª´ng block c√¢u h·ªèi theo s·ªë th·ª© t·ª±
    blocks = re.split(r'\n(?=\d+\.)', text)
    questions = []

    for block in blocks:
        block = block.strip()
        if not block or not re.match(r'^\d+\.', block):
            continue

        # Xo√° d√≤ng Ref... n·∫øu c√≥
        block = re.sub(r'(?i)Ref.*', '', block)

        # T√°ch d√≤ng ƒë·∫ßu l√†m c√¢u h·ªèi
        lines = [l.strip() for l in block.split("\n") if l.strip()]
        if not lines:
            continue

        # Gh√©p c√°c d√≤ng l·∫°i n·∫øu Word ng·∫Øt gi·ªØa c√¢u h·ªèi / ƒë√°p √°n
        joined = " ".join(lines)
        # T√¨m c√°c ƒë√°p √°n a,b,c,d trong chu·ªói
        opt_pat = re.compile(r'(?P<star>\*)?\s*(?P<letter>[A-Da-d])\s*(?:\.|\))\s*')
        matches = list(opt_pat.finditer(joined))
        if not matches:
            continue

        # C√¢u h·ªèi l√† ph·∫ßn tr∆∞·ªõc ƒë√°p √°n ƒë·∫ßu ti√™n
        q_text = clean_text(joined[:matches[0].start()])

        opts, answer = [], ""
        for idx, m in enumerate(matches):
            start = m.end()
            end = matches[idx+1].start() if idx+1 < len(matches) else len(joined)
            opt_body = clean_text(joined[start:end])
            letter = m.group("letter").lower()
            option_text = f"{letter}. {opt_body}"
            opts.append(option_text)
            if m.group("star"):
                answer = option_text

        if opts:
            if not answer:
                answer = opts[0]
            questions.append({"question": q_text, "options": opts, "answer": answer})

    return questions

# ====================================================
# üñ•Ô∏è GIAO DI·ªÜN STREAMLIT
# ====================================================
st.set_page_config(page_title="Ng√¢n h√†ng tr·∫Øc nghi·ªám", layout="wide")
st.title("üìö Ng√¢n h√†ng tr·∫Øc nghi·ªám")

bank_choice = st.selectbox("Ch·ªçn ng√¢n h√†ng:", ["Ng√¢n h√†ng K·ªπ thu·∫≠t", "Ng√¢n h√†ng Lu·∫≠t"])
source = "cabbank.docx" if "K·ªπ thu·∫≠t" in bank_choice else "lawbank.docx"

# ƒê·ªçc d·ªØ li·ªáu
if "K·ªπ thu·∫≠t" in bank_choice:
    questions = parse_cabbank(source)
else:
    questions = parse_lawbank(source)

if not questions:
    st.error("‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c c√¢u h·ªèi n√†o. Ki·ªÉm tra file .docx ho·∫∑c ƒë·ªãnh d·∫°ng.")
    st.stop()

st.success(f"‚úÖ ƒê√£ ƒë·ªçc ƒë∆∞·ª£c {len(questions)} c√¢u h·ªèi t·ª´ {bank_choice}.")

# ====================================================
# üß≠ TAB CH·ª®C NƒÇNG
# ====================================================
tab1, tab2 = st.tabs(["üß† L√†m b√†i", "üîç Tra c·ª©u to√†n b·ªô c√¢u h·ªèi"])

# ====================================================
# TAB 1: L√ÄM B√ÄI
# ====================================================
with tab1:
    group_size = 10
    TOTAL = len(questions)
    num_groups = math.ceil(TOTAL / group_size)
    group_labels = [f"C√¢u {i*group_size+1} - {min((i+1)*group_size, TOTAL)}" for i in range(num_groups)]

    selected_group = st.selectbox("Ch·ªçn nh√≥m c√¢u:", group_labels)
    start = group_labels.index(selected_group) * group_size
    end = min(start + group_size, TOTAL)
    batch = questions[start:end]

    if "submitted" not in st.session_state:
        st.session_state.submitted = False

    if not st.session_state.submitted:
        for i, q in enumerate(batch, start=start + 1):
            st.markdown(f"**{i}. {q['question']}**")
            st.radio("", q["options"], key=f"q_{i}")
            st.markdown("---")

        if st.button("‚úÖ N·ªôp b√†i"):
            st.session_state.submitted = True
            st.rerun()
    else:
        score = 0
        for i, q in enumerate(batch, start=start + 1):
            selected = st.session_state.get(f"q_{i}")
            if clean_text(selected) == clean_text(q["answer"]):
                st.success(f"{i}. ‚úÖ {q['question']} ‚Äî {q['answer']}")
                score += 1
            else:
                st.error(f"{i}. ‚ùå {q['question']} ‚Äî ƒê√°p √°n ƒë√∫ng: {q['answer']}")
        st.subheader(f"üéØ K·∫øt qu·∫£: {score}/{len(batch)}")

        if st.button("üîÅ L√†m l·∫°i nh√≥m n√†y"):
            for i in range(start + 1, end + 1):
                st.session_state.pop(f"q_{i}", None)
            st.session_state.submitted = False
            st.rerun()

# ====================================================
# TAB 2: TRA C·ª®U C√ÇU H·ªéI
# ====================================================
with tab2:
    st.markdown("### üîé Tra c·ª©u to√†n b·ªô c√¢u h·ªèi")

    df = pd.DataFrame([
        {
            "STT": i + 1,
            "C√¢u h·ªèi": q["question"],
            "ƒê√°p √°n A": q["options"][0] if len(q["options"]) > 0 else "",
            "ƒê√°p √°n B": q["options"][1] if len(q["options"]) > 1 else "",
            "ƒê√°p √°n C": q["options"][2] if len(q["options"]) > 2 else "",
            "ƒê√°p √°n D": q["options"][3] if len(q["options"]) > 3 else "",
            "ƒê√°p √°n ƒë√∫ng": q["answer"],
        }
        for i, q in enumerate(questions)
    ])

    keyword = st.text_input("üîç T√¨m theo t·ª´ kh√≥a (c√¢u h·ªèi ho·∫∑c ƒë√°p √°n):").strip().lower()
    if keyword:
        df_filtered = df[df.apply(lambda row: keyword in " ".join(row.values.astype(str)).lower(), axis=1)]
    else:
        df_filtered = df

    st.write(f"Hi·ªÉn th·ªã {len(df_filtered)}/{len(df)} c√¢u h·ªèi")
    st.dataframe(df_filtered, use_container_width=True)

    csv = df_filtered.to_csv(index=False).encode("utf-8-sig")
    st.download_button("‚¨áÔ∏è T·∫£i xu·ªëng danh s√°ch (CSV)", csv, "ngan_hang_cau_hoi.csv", "text/csv")
